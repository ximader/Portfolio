# Проект спринта 17 : Машинное обучение для текстов

## Задача

Интернет-магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.

## Вывод

Для проекта была применена модель BERT с предварительно предобученными весами `unitary/toxic-bert`.
Ввиду длительного расчета и случающихся ошибок с перезагрузкой Kernel, добавил механизм сохранения и загрузки промежуточных результатов, а именно:

- создана папка и механизм сохранения в нее промежуточных данных токенизации и эмбеддинга
- перед запуском просчета токенизации и эмбеддинга проводится проверка наличия в папке ранее полученных результатов
- непосредственно запуск расчетов производится только при отсутствии ранее полученных результатов

Для ускорения расчетов использовался GPU. Итоговый прирост скорости более, чем в 40 раз (20+ часов на CPU AMD Ryzen 5 2600 6 Core против 0.5 часа на GPU Geforce RTX 2060)

Для финальной классификации сообщений по их эмбеддингам из BERT были обучен набор моделей, лучшей из которых по метрике F1 стал DecisionTreeClassifier с параметрами {'max_depth': 20, 'n_estimators': 10}

Результат метрики F1 на тестовой выборке 0.938973

## Используемые библиотеки

pandas
torch
sklearn
tqdm
